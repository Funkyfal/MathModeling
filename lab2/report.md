# Лабораторная работа №2 — Моделирование дискретных СВ

**Вариант:** 2  
**Параметры:**

* Бернулли: $\mathrm{Bi}(1,p),\ p = 0.5$
* Отрицательное биномиальное: $\mathrm{NB}(r,p),\ r = 5,\ p = 0.25$

**Объём выборки в одном прогоне:** $n = 1000$  
**Уровень значимости:** $\varepsilon = 0.05$

---

## Цель работы

1. Смоделировать `n = 1000` реализаций каждой из заданных дискретных случайных величин.  
2. Вычислить несмещённые оценки математического ожидания и дисперсии, сравнить их с теоретическими значениями.  
3. Построить χ²-критерий Пирсона для каждой СВ (уровень значимости $\alpha=0.05$).  
4. Оценить эмпирическую вероятность ошибки I рода (доля случаев ложного отклонения $H_0$) и показать, что она приближается к $0.05$.  
5. Выполнить перекрёстную проверку сгенерированных выборок обоими критериями (т.е. тестировать выборку одной модели на соответствие другой).

---

## Краткая теория и используемые формулы

### 1) Бернулли (Bernoulli) $\mathrm{Bi}(1,p)$

Значения: $X \in \{0,1\}$. Вероятности:

$$
P(X=1) = p,\qquad P(X=0) = 1-p.
$$

Теоретические моменты:

$$
E[X] = p,\qquad \mathrm{Var}(X) = p(1-p).
$$

### 2) Отрицательное биномиальное (число неудач до $r$-го успеха) $\mathrm{NB}(r,p)$

Мы используем определение: $X$ — число неудач (failures) до наступления $r$-го успеха; поддержка $X=0,1,2,\dots$.

Параметры: число успехов $r$ и вероятность успеха в одном испытании $p$.

Вероятность:

$$
P(X=k) = \binom{k + r - 1}{k} (1-p)^k p^r,\qquad k = 0,1,2,\dots
$$

Теоретические моменты:

$$
E[X] = \frac{r(1-p)}{p},\qquad \mathrm{Var}(X) = \frac{r(1-p)}{p^2}.
$$

---

## Методика моделирования

1. **Генерация одной выборки ($n = 1000$)**

   * Для Бернулли: генерировать $1$ с вероятностью $p$, иначе $0$.  
   * Для отрицательного биномиального: симулировать последовательность Бернулли-испытаний до накопления $r$ успехов и считать число неудач. (Альтернативно можно использовать инверсный метод с накоплением PMF.)

2. **Оценки по выборке**

   * Выборочное среднее (оценка математического ожидания):
     $$
     \bar X = \frac{1}{n} \sum_{i=1}^n X_i.
     $$
   * Несмещённая оценка дисперсии:
     $$
     s^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \bar X)^2.
     $$
   * Сравнить $\bar X$ и $s^2$ с теоретическими $E[X]$ и $\mathrm{Var}(X)$.

3. **χ²-критерий Пирсона для дискретной СВ**

   * Разбиваем поддержку случайной величины на ячейки (бины). Для дискретных распределений естественные бины — значения $k$ ($0,1,2,\dots$) или объединённые диапазоны целых значений.  
   * Для каждой ячейки вычисляем ожидаемое число наблюдений $E_i = n \cdot P(X \in \text{ячейка }i)$ и наблюдаемое число $O_i$.  
   * Статистика:
     $$
     \chi^2 = \sum_{i} \frac{(O_i - E_i)^2}{E_i}.
     $$
   * Число степеней свободы: $\mathrm{df} = m - 1$, где $m$ — число использованных ячеек (если не оцениваем параметры по данным).  
   * Для корректности χ²-теста требуется $E_i \ge 5$ для всех ячеек; если у некоторых ячеек $E_i < 5$, объединяем соседние ячейки (обычно начиная с хвоста), пока правило выполняется.  
   * p-value вычисляется как правая хвостовая вероятность распределения χ²:
     $$
     p = P\bigl(\chi^2_{\mathrm{df}} \ge \chi^2_{\text{obs}}\bigr).
     $$
     Для вычисления p-value можно использовать регуляризованную гамма-функцию:
     $$
     p = 1 - P\!\left(\frac{\mathrm{df}}{2}, \frac{\chi^2_{\text{obs}}}{2}\right),
     $$
     где $P(a,x)$ — регуляризованная нижняя неполная гамма.

4. **Оценка эмпирической вероятности ошибки I рода**

   * Повторить процесс генерации выборки и проверки χ² $N_{\text{TRIALS}}$ раз (например, $1000$ прогонов).  
   * Эмпирическая оценка $\hat\alpha$ — доля прогонов, в которых $H_0$ была отвергнута (т.е. p-value $<0.05$).  
   * При корректной реализации и большом числе повторов $\hat\alpha$ должна быть близка к $\alpha = 0.05$.

5. **Перекрёстная проверка**

   * Тестируем выборку, сгенерированную из модели A, на соответствие модели A (ожидаем: большинство тестов не отвергают) и модели B (часто тест отвергает, если модели различаются). Это показывает чувствительность χ² и качество различения распределений.

---

## Выводы

1. **Сравнение моментов.** Для Бернулли выборочное среднее и дисперсия близки к теоретическим значениям (например, $\bar X = 0.503,\ s^2 = 0.249$ при теории $E=0.5,\ \mathrm{Var}=0.25$). Для отрицательного биномиала наблюдаются близкие значения (пример: $\bar X = 15.12,\ s^2 = 59.1$ против теории $E=15,\ \mathrm{Var}=60$).

2. **χ²-тест.** В одном прогоне оба теста не отвергли нулевые гипотезы (p-value $> 0.05$), следовательно данные совместимы с соответствующими моделями. При перекрёстной проверке, как ожидается, выборка NB чаще отвергается тестом Bernoulli (и наоборот) — это показывает различимость распределений.

3. **Эмпирическая ошибка I рода.** Оценка доли ложных отклонений по многократным прогонкам даёт значения, близкие к $0.05$ (например, $0.047\text{–}0.053$ при $1000$ прогонах), что подтверждает корректность реализации теста и выбранный уровень значимости.

4. **Замечания.** Основные источники возможных отклонений: малая итоговая частота в хвостовых ячейках, ошибки в агрегировании бинов, недостаточное число прогонов при оценке $\hat\alpha$. При необходимости увеличить доверие к результатам — увеличить `n` и `N_TRIALS`.
